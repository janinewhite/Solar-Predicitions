{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5daa5292ae1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read in json data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_tucson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\jhonp\\Desktop\\Solar-Predictions\\data\\Weather\\Yuma.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# # Grab the first row for the header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# new_header_2018 = df_2018.iloc[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 849\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m-> 1093\u001b[1;33m                 \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m             )\n\u001b[0;32m   1095\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "# Read in json data\n",
    "df_tucson = pd.read_json (r'C:\\Users\\jhonp\\Desktop\\Solar-Predictions\\data\\Weather\\Yuma.json')\n",
    "\n",
    "# # Grab the first row for the header\n",
    "# new_header_2018 = df_2018.iloc[0]\n",
    "# # Take the data less the header row\n",
    "# df_2018 = df_2018[1:]\n",
    "# # Set the header row as the df header\n",
    "# df_2018.columns = new_header_2018\n",
    "\n",
    "# # Split up the Name column and retain only city name\n",
    "# df_2018[['Location','Other']] = df_2018.NAME.str.split(\",\",expand=True) \n",
    "\n",
    "# # Drop the state and place columns\n",
    "# df_2018 = df_2018.drop('GEO_ID', 1)\n",
    "# df_2018 = df_2018.drop('B19013_001M', 1)\n",
    "# df_2018 = df_2018.drop('NAME', 1)\n",
    "# df_2018 = df_2018.drop('state', 1)\n",
    "# df_2018 = df_2018.drop('place', 1)\n",
    "# df_2018 = df_2018.drop('B19013_001EA', 1)\n",
    "# df_2018 = df_2018.drop('B19013_001MA', 1)\n",
    "# df_2018 = df_2018.drop('Other', 1)\n",
    "\n",
    "# # Add the year column \n",
    "# df_2018.insert(2, 'Year', '2018', True)\n",
    "\n",
    "# # # Reorder columns\n",
    "# columns_2018 = ['Location','B19013_001E', 'Year']\n",
    "# df_2018 = df_2018[columns_2018]\n",
    "\n",
    "# # # Rename columns\n",
    "# df_2018.rename(columns = {'B19013_001E':'Household Income(Annual)'}, inplace = True)\n",
    "\n",
    "print(df_tucson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in json data\n",
    "df_2017 = pd.read_json (r'C:\\Users\\klsom\\Desktop\\Solar-Predictions\\data\\Income & Population\\Income\\2017.json')\n",
    "\n",
    "# Grab the first row for the header\n",
    "new_header_2017 = df_2017.iloc[0]\n",
    "# Take the data less the header row\n",
    "df_2017 = df_2017[1:]\n",
    "# Set the header row as the df header\n",
    "df_2017.columns = new_header_2017\n",
    "\n",
    "# Split up the Name column and retain only city name\n",
    "df_2017[['Location','Other']] = df_2017.NAME.str.split(\",\",expand=True) \n",
    "\n",
    "# Drop the state and place columns\n",
    "df_2017 = df_2017.drop('GEO_ID', 1)\n",
    "df_2017 = df_2017.drop('B19013_001M', 1)\n",
    "df_2017 = df_2017.drop('NAME', 1)\n",
    "df_2017 = df_2017.drop('state', 1)\n",
    "df_2017 = df_2017.drop('place', 1)\n",
    "df_2017 = df_2017.drop('B19013_001EA', 1)\n",
    "df_2017 = df_2017.drop('B19013_001MA', 1)\n",
    "df_2017 = df_2017.drop('Other', 1)\n",
    "\n",
    "# Add the year column \n",
    "df_2017.insert(2, 'Year', '2017', True)\n",
    "\n",
    "# # Reorder columns\n",
    "columns_2017 = ['Location','B19013_001E', 'Year']\n",
    "df_2017 = df_2017[columns_2017]\n",
    "\n",
    "# # Rename columns\n",
    "df_2017.rename(columns = {'B19013_001E':'Household Income(Annual)'}, inplace = True)\n",
    "\n",
    "print(df_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in json data\n",
    "df_2016 = pd.read_json (r'C:\\Users\\klsom\\Desktop\\Solar-Predictions\\data\\Income & Population\\Income\\2016.json')\n",
    "\n",
    "# Grab the first row for the header\n",
    "new_header_2016 = df_2016.iloc[0]\n",
    "# Take the data less the header row\n",
    "df_2016 = df_2016[1:]\n",
    "# Set the header row as the df header\n",
    "df_2016.columns = new_header_2016\n",
    "\n",
    "# Split up the Name column and retain only city name\n",
    "df_2016[['Location','Other']] = df_2016.NAME.str.split(\",\",expand=True) \n",
    "\n",
    "# # Drop the state and place columns\n",
    "df_2016 = df_2016.drop('NAME', 1)\n",
    "df_2016 = df_2016.drop('B19013_001M', 1)\n",
    "df_2016 = df_2016.drop('B19013_001EA', 1)\n",
    "df_2016 = df_2016.drop('B19013_001MA', 1)\n",
    "df_2016 = df_2016.drop('state', 1)\n",
    "df_2016 = df_2016.drop('place', 1)\n",
    "df_2016 = df_2016.drop('Other', 1)\n",
    "\n",
    "# Add the year column \n",
    "df_2016.insert(2, 'Year', '2016', True)\n",
    "\n",
    "# # Reorder columns\n",
    "columns_2016 = ['Location','B19013_001E', 'Year']\n",
    "df_2016 = df_2016[columns_2016]\n",
    "\n",
    "# # Rename columns\n",
    "df_2016.rename(columns = {'B19013_001E':'Household Income(Annual)'}, inplace = True)\n",
    "\n",
    "print(df_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in json data\n",
    "df_2015 = pd.read_json (r'C:\\Users\\klsom\\Desktop\\Solar-Predictions\\data\\Income & Population\\Income\\2015.json')\n",
    "\n",
    "# Grab the first row for the header\n",
    "new_header_2015 = df_2015.iloc[0]\n",
    "# Take the data less the header row\n",
    "df_2015 = df_2015[1:]\n",
    "# Set the header row as the df header\n",
    "df_2015.columns = new_header_2015\n",
    "\n",
    "# Split up the Name column and retain only city name\n",
    "df_2015[['Location','Other']] = df_2015.NAME.str.split(\",\",expand=True) \n",
    "\n",
    "# Drop the state and place columns\n",
    "df_2015 = df_2015.drop('GEO_ID', 1)\n",
    "df_2015 = df_2015.drop('B19013_001M', 1)\n",
    "df_2015 = df_2015.drop('NAME', 1)\n",
    "df_2015 = df_2015.drop('state', 1)\n",
    "df_2015 = df_2015.drop('place', 1)\n",
    "df_2015 = df_2015.drop('B19013_001EA', 1)\n",
    "df_2015 = df_2015.drop('B19013_001MA', 1)\n",
    "df_2015 = df_2015.drop('Other', 1)\n",
    "\n",
    "# Add the year column \n",
    "df_2015.insert(2, 'Year', '2015', True)\n",
    "\n",
    "# # Reorder columns\n",
    "columns_2015 = ['Location','B19013_001E', 'Year']\n",
    "df_2015 = df_2015[columns_2015]\n",
    "\n",
    "# # Rename columns\n",
    "df_2015.rename(columns = {'B19013_001E':'Household Income(Annual)'}, inplace = True)\n",
    "\n",
    "print(df_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in json data\n",
    "df_2014 = pd.read_json (r'C:\\Users\\klsom\\Desktop\\Solar-Predictions\\data\\Income & Population\\Income\\2014.json')\n",
    "\n",
    "# Grab the first row for the header\n",
    "new_header_2014 = df_2014.iloc[0]\n",
    "# Take the data less the header row\n",
    "df_2014 = df_2014[1:]\n",
    "# Set the header row as the df header\n",
    "df_2014.columns = new_header_2014\n",
    "\n",
    "# Split up the Name column and retain only city name\n",
    "df_2014[['Location','Other']] = df_2014.NAME.str.split(\",\",expand=True) \n",
    "\n",
    "# Drop the state and place columns\n",
    "df_2014 = df_2014.drop('GEO_ID', 1)\n",
    "df_2014 = df_2014.drop('B19013_001M', 1)\n",
    "df_2014 = df_2014.drop('NAME', 1)\n",
    "df_2014 = df_2014.drop('state', 1)\n",
    "df_2014 = df_2014.drop('place', 1)\n",
    "df_2014 = df_2014.drop('B19013_001EA', 1)\n",
    "df_2014 = df_2014.drop('B19013_001MA', 1)\n",
    "df_2014 = df_2014.drop('Other', 1)\n",
    "\n",
    "# Add the year column \n",
    "df_2014.insert(2, 'Year', '2014', True)\n",
    "\n",
    "# # Reorder columns\n",
    "columns_2014 = ['Location','B19013_001E', 'Year']\n",
    "df_2014 = df_2014[columns_2014]\n",
    "\n",
    "# # Rename columns\n",
    "df_2014.rename(columns = {'B19013_001E':'Household Income(Annual)'}, inplace = True)\n",
    "\n",
    "print(df_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in json data\n",
    "df_2013 = pd.read_json (r'C:\\Users\\klsom\\Desktop\\Solar-Predictions\\data\\Income & Population\\Income\\2013.json')\n",
    "\n",
    "# Grab the first row for the header\n",
    "new_header_2013 = df_2013.iloc[0]\n",
    "# Take the data less the header row\n",
    "df_2013 = df_2013[1:]\n",
    "# Set the header row as the df header\n",
    "df_2013.columns = new_header_2013\n",
    "\n",
    "# Split up the Name column and retain only city name\n",
    "df_2013[['Location','Other']] = df_2013.NAME.str.split(\",\",expand=True) \n",
    "\n",
    "# Drop the state and place columns\n",
    "df_2013 = df_2013.drop('GEO_ID', 1)\n",
    "df_2013 = df_2013.drop('B19013_001M', 1)\n",
    "df_2013 = df_2013.drop('NAME', 1)\n",
    "df_2013 = df_2013.drop('state', 1)\n",
    "df_2013 = df_2013.drop('place', 1)\n",
    "df_2013 = df_2013.drop('B19013_001EA', 1)\n",
    "df_2013 = df_2013.drop('B19013_001MA', 1)\n",
    "df_2013 = df_2013.drop('Other', 1)\n",
    "\n",
    "# Add the year column \n",
    "df_2013.insert(2, 'Year', '2013', True)\n",
    "\n",
    "# # Reorder columns\n",
    "columns_2013 = ['Location','B19013_001E', 'Year']\n",
    "df_2013 = df_2013[columns_2013]\n",
    "\n",
    "# # Rename columns\n",
    "df_2013.rename(columns = {'B19013_001E':'Household Income(Annual)'}, inplace = True)\n",
    "\n",
    "print(df_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_to_merge = [df_2018, df_2017, df_2016, df_2015, df_2014, df_2013]\n",
    "income_df = pd.concat(dfs_to_merge, sort=True)\n",
    "print(income_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_df.to_csv(r'Income.csv')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
